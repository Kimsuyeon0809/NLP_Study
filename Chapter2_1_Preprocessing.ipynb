{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 02. 텍스트 전처리\n",
        "\n",
        "p 49~"
      ],
      "metadata": {
        "id": "g2TLnp3z6mBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.토큰화 (Tokenization)\n",
        "- 코퍼스를 토큰으로 나누는 작업\n",
        "- NLTK : 영어 토큰화 도구 제공\n",
        "- KoNLPY"
      ],
      "metadata": {
        "id": "ZI3u9GYX63D4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-1) 단어 토큰화(Word Tokenization)\n",
        "- 토큰의 기준을 단어(단어구, 의미를 갖는 문자열)로 해서 분리\n"
      ],
      "metadata": {
        "id": "CJOYSzwR8bT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'를 어떻게 분리할 것인가에 대한 선택의 문제 : 목적에 따라 함수 사용하거나  직접 정의"
      ],
      "metadata": {
        "id": "YlTqEx4T_MBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIjrEhRV_VQF",
        "outputId": "a0ec9716-938b-4e50-e801-c0f9c51ea653"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XRueI2e16iBh"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
        "# word_tokenize() : Don’t 를 Do 와 n’t 로 분리, 반면 Jone’s 는 Jone 과’s 로 분리"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0D3MEZW_KgG",
        "outputId": "2ffdaf43-dab1-4831-c44c-ddee902cdabb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
        "# WordPunctTokenizer() : Don’t 를 Don 과 ’와 t 로 분리, 이와 마찬가지로 Jone’s 를 Jone 과 ’와 s 로 분리"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jswi0fCo_0m3",
        "outputId": "45271044-9ed8-4375-8beb-7df0fb7b6ede"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
        "# text_to_word_sequence() : ' 보존(분리하지 않음)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbKUvAf-AJjk",
        "outputId": "580c683c-44b2-4e28-8f10-fe3ff3ac2c1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-2) 토큰화 시 고려사항\n",
        "- 구두점이나 특수문자 단순 제외 x (Ph.D처럼 단어 자체 구두점 있는 경우 있음 / 숫자 사이 , 등)\n",
        "- ’가 사용된 줄임말 펼치기 처리 / New York처럼 한 단어 내 띄어쓰기 있는 경우 한 토큰으로 처리 필요\n",
        "- Penn Treebank Tokenization : 표준 토큰화 방법(규칙 1. 하이푼으로 구성된 단어는 하나로 유지한다./\n",
        "규칙 2. doesn’t 와 같이 아포스트로피로’ 접어’ 가 함께하는 단어는 분리해준다.)"
      ],
      "metadata": {
        "id": "zPwbg0zvBdp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Penn Treebank Tokenization\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 :',tokenizer.tokenize(text))\n",
        "# 결과 : -(하이푼)이 들어간 home-based는 한 단어로 유지, '로 구성된 접어는 분리"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pdmXjRYAl4s",
        "outputId": "7a9463d2-7145-4167-c2e1-32e5ac700401"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-3) 문장 토큰화 = 토큰 단위가 문장 = 문장분류\n",
        "- !나 ?는명확한 문장 구분자이지만, .은 그렇지 않음\n"
      ],
      "metadata": {
        "id": "EVD-N9u4F8Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sent_tokenize() : 영어 문장 토큰화 수행\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "print('문장 토큰화1 :',sent_tokenize(text))"
      ],
      "metadata": {
        "id": "3gdWmeKLFnBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2ae1ee-5deb-49e3-8db5-90ad199f53e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화1 : ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 마침표가 다수 포함된 문장의 경우로 sent_tokenize() 테스트 -> 문장  중간 .를 기준으로 문장 분리하지 않음\n",
        "# = 단순히 마침표를 구분자로 하지 않음\n",
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print('문장 토큰화2 :',sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nQZETs79ucy",
        "outputId": "5d5bc955-04a3-4a57-dea6-d736744d6eae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KSS(Korean Sentence Splitter) : 한국어문장 토큰화\n",
        "!pip install kss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu_sKUml_9U3",
        "outputId": "55586ed1-cee0-4d4f-9d52-4bf3aa258d6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kss\n",
            "  Downloading kss-4.5.4.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting emoji==1.2.0 (from kss)\n",
            "  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kss) (2023.12.25)\n",
            "Collecting pecab (from kss)\n",
            "  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (1.25.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (14.0.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (7.4.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.1)\n",
            "Building wheels for collected packages: kss, pecab\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-4.5.4-py3-none-any.whl size=54464 sha256=ad1b3292fdb177c7e25c34deff785b8c40b9553e5dd032642db763e2c3d29b9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/7b/ba/e620ef5d96a61cdd83bdee4c2bb4aec8a74de5d72fcbb00e80\n",
            "  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646665 sha256=ff23075c6bd0cda1292496e0bcc4f91f8d5e18060fed453efbb0303f1b63e1ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/6f/b4/ab61b8863d7d8b1409def8ae31adcaa089fa91b8d022ec309d\n",
            "Successfully built kss pecab\n",
            "Installing collected packages: emoji, pecab, kss\n",
            "Successfully installed emoji-1.2.0 kss-4.5.4 pecab-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KSS(Korean Sentence Splitter) : 한국어문장 토큰화\n",
        "import kss\n",
        "\n",
        "text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
        "print('한국어 문장 토큰화 :',kss.split_sentences(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq5k13b--KOv",
        "outputId": "9a706a27-3335-475e-da14-d01ea8fcb983"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
            "For your information, Kss also supports mecab backend.\n",
            "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
            "Please refer to following web sites for details:\n",
            "- mecab: https://github.com/hyunwoongko/python-mecab-kor\n",
            "- konlpy.tag.Mecab: https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-4) 한국어 토큰화의 어려움\n",
        "- 영어와 달리 띄어쓰기만으로 토큰화 불가 (어절 토큰화 != 단어 토큰화) -> 한국어가 '교착어'(조사, 어미등 붙여서 말을 만드는 언어)이기 때문\n",
        "- 교착어의 특성 : 같은 단어에 서로 다른 조사가 붙음(그가, 그에게, 그는..)-> 조사 분리 필요\n",
        "- 형태소 : 뜻을 가진 가장 작은 말의 단위, 자립형태소/의존형태소로 나뉨\n",
        "- 자립 형태소 : 접사, 어미, 조사와 상관없이 자립하여 사용하는 형태소. (체언, 수식언, 감탄사 등)\n",
        "- 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소(접사, 어미, 조사, 어간)\n",
        "- 영어에 비해 띄어쓰기가 틀렸거나 지켜지지 않은 코퍼스가 많음"
      ],
      "metadata": {
        "id": "9OCFofnRAhCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-5) 품사 태깅\n",
        "- 같은 단어도 품사에 따라 뜻이 다름 -> 품사로 단어 의미 파악\n",
        "- 품사 태깅 : 단어가 어떤 품사로 쓰였는지 구분하는 작업\n",
        "- NLTK :  Penn Treebank POS Tags 기준 사용하여 품사 태깅(PRP : 인칭 대명사, VBP : 동사, RB : 부사, VBG : 현재부사, IN : 전치사, NNP : 고유 명사, NNS : 복수형 명사, CC : 접속사, DT : 관사)\n",
        "- KoNLPy : 형태소 분석기 Okt(Open Korea Text), 메캅 (Mecab), 코모란 (Komoran), 한나눔 (Hannanum), 꼬꼬마 (Kkma) 사용 가능"
      ],
      "metadata": {
        "id": "JaAEEhA9Es6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "metadata": {
        "id": "TOtrj8t1_8OI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 품사 태깅 : NLTK\n",
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "tokenized_sentence = word_tokenize(text)\n",
        "\n",
        "print('단어 토큰화 :',tokenized_sentence)\n",
        "print('품사 태깅 :',pos_tag(tokenized_sentence)) #  토큰화를 수행한 결과를 입력으로 품사 태깅"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJTElxkNFMTq",
        "outputId": "25bec5d9-861f-4b36-9a14-c7a55111a4f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화 : ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n",
            "품사 태깅 : [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOC1V_4THDEq",
        "outputId": "e9790580-482d-4bbe-c505-4eda3ce76e43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KoNLPy의 Okt, 꼬꼬마 두 개의 형태소 분석기 사용해 단어(형태) 토큰화, 품사 태\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkma()"
      ],
      "metadata": {
        "id": "7BgFOsjoFOzU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Okt() 사용\n",
        "print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXJ8UAN8HWqE",
        "outputId": "74a1ac3f-6291-4c01-bcce-da1cd48bd021"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OKT 형태소 분석 : ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n",
            "OKT 품사 태깅 : [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n",
            "OKT 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kkma() 사용\n",
        "print('꼬꼬마 형태소 분석 :',kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) # morphs : 형태소 추출\n",
        "print('꼬꼬마 품사 태깅 :',kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) # pos : 품사 태깅\n",
        "print('꼬꼬마 명사 추출 :',kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  # nouns : 명사 추출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPMV5nrjG26S",
        "outputId": "418ffc5f-4f87-4465-81ca-4296a9e626e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "꼬꼬마 형태소 분석 : ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n",
            "꼬꼬마 품사 태깅 : [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n",
            "꼬꼬마 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.  정제(Cleaning)와 정규화(Normalization)\n",
        "-  정제 (cleaning) : 코퍼스에서 노이즈 데이터 제거한다.\n",
        "- 정규화 (normalization) : 표현 방법이 다른 단어들 통합 -> 같은 단어로\n",
        "\n",
        "<정규화 방법>\n",
        "\n",
        "- 표기가 다른 단어들 통합 : 어간 추출, 표제어 추출\n",
        "- 대,소문자 통합(US와 us처럼 무조건 통합하면 안되는 경우도 있음 -> 언제 변환할지 결정하는 머신 러닝 시퀀스 모델 사용하는 방법 등이 있음)\n",
        "\n",
        "<정제>\n",
        "- 불필요한 단어 제거 : 노이즈 데이터 제거(의미 없는 글, 목적에 불필요한 단어 등) -> 불용어, 등장 빈도 적은 단어, 길이 짧은 단어 제거 등의 방법\n"
      ],
      "metadata": {
        "id": "Z_qnF3t5I7sH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<정규표현식>\n",
        "- 정규표현식으로 노이즈데이터 제거 가능"
      ],
      "metadata": {
        "id": "y1rcmAWYrRxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
        "\n",
        "# 길 이 가 1~2인 단 어 들 을 정 규 표 현 식 을 이 용 하 여 삭 제\n",
        "shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "print(shortword.sub('', text))"
      ],
      "metadata": {
        "id": "IwXkmQpQHa7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4129ad-dfc4-4b72-e488-a389511fffb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " was wondering anyone out there could enlighten this car.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 어간 (stemming) 추출과 표제어 (lemmatization) 추출\n",
        "- 정규화 기법 중 하나, 단어 개수 줄일 수 있음\n",
        "- 다른 단어지만 한 단어로 일반화 가능하다면 일반화 -> 단어 수 감소\n",
        "- 단어 빈도수 기반 문제해결 방법인 BoW(Bag of Words) 표현을 사용하는 자연어 처리 문제에서 주로 사용\n",
        "- 자연어 처리에서 정규화의 지향점 = 코퍼스의 복잡성 줄이기"
      ],
      "metadata": {
        "id": "diufbM7rvhip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-1) 표제어 추출\n",
        "- 표제어 : 기본 사전형 단어\n",
        "- 서로 다른 형태의 단어의 뿌리를 찾아 단어 개수 줄일 수 있는지 판단 ex) am, are, is -> be\n",
        "- 형태학 : 형태소로부터 단어들을 만들어가는 학문\n",
        "- 형태소 : 의미를 가진 가장 작은 단위. 어간과 접사가 존재\n",
        "- 어간 : 단어의 의미를 담고 있는 핵심 부분\n",
        "- 접사 : 단어에 추가적인 의미 주는 부분\n",
        "- 형태학적 파싱 : 어간과 접사로 분리하는작업 ex) cats -> cat, s"
      ],
      "metadata": {
        "id": "jdh5qyTdhjqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ave2LJZjmvtd",
        "outputId": "4cfbf769-04df-43df-c285-e130432ff218"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 표제어 추출 도구 WordNetLemmatizer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "print('표제어 추출 전 :',words)\n",
        "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])\n",
        "# dies의 표제어가 dy로 나오는 등 잘못된 결과도 있음 -> 품사 정보 알려주면 해결"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVwOSM1wrn9U",
        "outputId": "d06fd51b-5799-4f9c-e248-597af28ba166"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dies의 품사가 동사임을 알려주고 표제어 추출\n",
        "print(lemmatizer.lemmatize('dies', 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjEKiQ-GkuUr",
        "outputId": "87ab8424-0f34-4399-9567-c5b1f4fb0645"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "die\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-2) 어간 추출\n",
        "- 정해진 규칙으로 단어의 어미 자르는 어림짐작의 작업 -> 추출 결과가 사전에 없을 수 있음\n",
        "- 포터 알고리즘의 어간 추출 규칙\n",
        "\n",
        "1) ALIZE → AL ex) formalize -> formal\n",
        "\n",
        "2) ANCE → 제거 ex) allowance -> allow\n",
        "\n",
        "3) ICAL → IC ex) electricical → electric"
      ],
      "metadata": {
        "id": "wQ6TE8Ojpf3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 포터 알고리즘 사용해 어간 추출\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "sentence = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "tokenized_sentence = word_tokenize(sentence) # 문장을 단어 단위로 토큰화\n",
        "\n",
        "print('어간 추출 전 :', tokenized_sentence) # 토큰화 한 단어들\n",
        "print('어간 추출 후 :',[stemmer.stem(word) for word in tokenized_sentence]) # 토큰화 한 단어들의 어간 추출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asWlTo-HpSn4",
        "outputId": "59e93e67-5697-47d2-e7d6-b37a13685b2e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
            "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['formalize', 'allowance', 'electricical']\n",
        "\n",
        "print('어간 추출 전 :',words)\n",
        "print('어간 추출 후 :',[stemmer.stem(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzSdX6Swp61r",
        "outputId": "5a040827-5c0e-41b4-90be-eb0436abb603"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['formalize', 'allowance', 'electricical']\n",
            "어간 추출 후 : ['formal', 'allow', 'electric']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어간 추출 모델 비교 : 포터 알고리즘과 랭커스터 스태머 알고리즘\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print('어간 추출 전 :', words)\n",
        "print('포터 스테머의 어간 추출 후:',[porter_stemmer.stem(w) for w in words])\n",
        "print('랭커스터 스테머의 어간 추출 후:',[lancaster_stemmer.stem(w) for w in words])\n",
        "# 코퍼스에 여러 스테머 적용 후 적합한 스테머 사용해야"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4iozMr6s2pz",
        "outputId": "8b88d4ec-a6f9-4a51-90ca-72fc9480fa67"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "포터 스테머의 어간 추출 후: ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
            "랭커스터 스테머의 어간 추출 후: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-3) 한국어 어간 추출\n",
        "- 5언 9품사 : 체언(명사, 대명사,수사), 수식언(관형사, 부사), 관계언(조사), 독립언(감탄사), 용언(동사, 형용사)\n",
        "- 용언 : 어간(원칙적으로 모양 변화x, 예외o) + 어미(용언 뒤에 붙어서 활용)\n",
        "- 규칙 활용 : 활용 시 어간 형태 변화 x\n",
        "- 불규칙 활용 : 활용 시 어간 형태 변화 o"
      ],
      "metadata": {
        "id": "3F-S5wQLuQcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 불용어 (Stopword)\n",
        "- 불용어 : 자주 등장하지만, 분석에 도움되지 않는 단어 ex) 조사, 접미사\n",
        "- 불용어 직접 정의 가능"
      ],
      "metadata": {
        "id": "nxZPwxTSzEZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-1) NLTK 불용어 확인"
      ],
      "metadata": {
        "id": "sYWoAUCi0aXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t_uUOeGtK1b",
        "outputId": "db89e7bd-7a0f-4588-ec71-116457280636"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "PE75Cu8g0es9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_list = stopwords.words('english') # NLTK가 정의한 불용어 리스트\n",
        "print('불용어 개수 :', len(stop_words_list))\n",
        "print('불용어 10개 출력 :',stop_words_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0uD4JX_0hyV",
        "outputId": "f5f6ef47-4e10-41b2-a99e-385abf536810"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 개수 : 179\n",
            "불용어 10개 출력 : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-2) NLTK 불용어 제거"
      ],
      "metadata": {
        "id": "yAmtTpBIeCOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Family is not an important thing. It's everything.\"\n",
        "stop_words = set(stopwords.words('english')) # 영어 불용어 stop_words 변수에 저장\n",
        "\n",
        "word_tokens = word_tokenize(example) # 코퍼스 토큰화\n",
        "\n",
        "result = [] # 불용어 제외한 코퍼스 담을 배열\n",
        "for word in word_tokens: # 토큰 순회하며\n",
        "    if word not in stop_words: # 불용어 리스트에 없는 토큰이면\n",
        "        result.append(word) # result에 삽입\n",
        "\n",
        "print('불용어 제거 전 :',word_tokens)\n",
        "print('불용어 제거 후 :',result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2mnZ93l0jzk",
        "outputId": "249c8177-9bce-4add-a8c2-ba0b8b7b5987"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
            "불용어 제거 후 : ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-3) 한국어에서 불용어 제거\n",
        "- 간단한 방법 : 토큰화 -> 조사, 접속사 제거\n",
        "- 명사, 형용사 중 불용어로 제거하고싶으면 직접 불용어 사전 생성"
      ],
      "metadata": {
        "id": "kPjqyMgJgr60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의로 불용어 선정해서 제거하는 경\n",
        "okt = Okt() # 인스턴스 생성 (클래스를 사용하기 위해 메모리 구조를 만듦)\n",
        "\n",
        "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\" # 직접 정의한 불용어\n",
        "\n",
        "stop_words = set(stop_words.split(' ')) # 문장 형태인 불용어들을 공백 기준 분리\n",
        "word_tokens = okt.morphs(example) # okt.morphs(): 텍스트를 형태소 단위로 분리(옵션 norm : 정규화, stem : 어간 추출)\n",
        "\n",
        "result = [word for word in word_tokens if not word in stop_words] # 리스트 컴프리헨션\n",
        "# word_tokens 순회하며 stop_words에 없으면 result 리스트에 추가 = 예시 문장의 토큰 중 불용어 아닌 토큰만 result 리스트에 추가\n",
        "\n",
        "print('불용어 제거 전 :',word_tokens)\n",
        "print('불용어 제거 후 :',result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwp6bZeOgNOE",
        "outputId": "147302f9-43c7-4bf7-e594-597aed798865"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전 : ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
            "불용어 제거 후 : ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 정규 표현식 (Regular Expression)\n",
        "- 정규 표현식 모듈 re\n",
        "- NLTK로 정규 표현식 이용해 토큰화"
      ],
      "metadata": {
        "id": "FM78gwoOj2kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-1) 정규표현식 모듈 re\n",
        "- 특정 규칙이 있는 텍스트 데이터 정제"
      ],
      "metadata": {
        "id": "qxnrYrntkbv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "i2qvd6-Pgv07"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- .(온점) : 한 개의 임의의 문자"
      ],
      "metadata": {
        "id": "TlUNuSupn0bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"a.c\") # 정규표현식에서 .(온점):한 개의 임의의 문자 # re.compile() : 정규식 객체 리턴\n",
        "r.search(\"kkk\") # 문자열 전체를 검색 -> 정규식과 매치되는지 조사\n",
        "# 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "k92EFFl3mGj3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\") # 임의의 문자 . 자리에 b가 들어간 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6ozY26mK2V",
        "outputId": "8d4ea851-b210-4f72-ea8a-0b0e799f05b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"a\") # 아무 결과 없음"
      ],
      "metadata": {
        "id": "R92bJT9amL-z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"akc\") # 임의의 문자 . 자리에 k가 들어간 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmL0V3GinaSM",
        "outputId": "5ff769e3-5489-4e3e-fbb0-b6cc6dbbf268"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='akc'>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ? : 앞의 문자 존재할수도, 존재하지 않을수도 있음 (문자가 0 or 1개)"
      ],
      "metadata": {
        "id": "k1ho6K-Vn6Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab?c\")\n",
        "r.search(\"abbc\") # 아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "n_dnz8IKnhPc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"ac\") # ? 앞 문자 b가 존재하지 않는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CBD8MZ1oDDV",
        "outputId": "067804fd-0f88-47d4-c1c5-ee1161e91a70"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ac'>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\") # ? 앞 문자 b가 존재하는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvwl6obkoGwf",
        "outputId": "bd6e9c23-a5f7-4dd1-d622-673f06a3b652"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"c\")\n",
        "r.search(\"ab\")\n",
        " # 아무 결과 없음 -> ? 직전 외에는 모두 있어야 함"
      ],
      "metadata": {
        "id": "LfdjdAIJoJJl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *(별) : 앞의 문자가 무한개로 존재할수도, 존재하지 않을수도 있음(문자가 0개 이상)"
      ],
      "metadata": {
        "id": "v-nhn7SRo0lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab*c\")\n",
        "r.search(\"ac\") # * 앞 문자가 없는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loJcam6boc7l",
        "outputId": "c7ffeb72-fd1f-483e-ad29-391019f6a510"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ac'>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbbbbbbbbbbbbbbbbbbbbbbbbc\") # * 앞 문자가 많은 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5rI-thBpr56",
        "outputId": "bd621078-4b87-40be-af58-5ef0fd6e99dd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 27), match='abbbbbbbbbbbbbbbbbbbbbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"akkkkkkc\") # 다른 문자가 많은 경우 -> match 안됨"
      ],
      "metadata": {
        "id": "tZQgTjP9puUV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- +: 앞의 문자가 최소 한 개 이상 존재 (문자가 1개 이상)"
      ],
      "metadata": {
        "id": "9e7Mcpvxp7Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab+c\")\n",
        "r.search(\"abc\") # + 앞 문자가 1개인 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjHYSWMXpwc7",
        "outputId": "b9384bd8-a207-49fa-a327-5b9243a4b9a7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbbbbbbbbbbbbbbbbbc\") # + 앞 문자가 많은 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvMk2rG-qF5y",
        "outputId": "0107c3b4-3d2f-435c-b878-c4693c654c98"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 20), match='abbbbbbbbbbbbbbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"ac\") # + 앞 문자가 없는 경우 -> match 안됨"
      ],
      "metadata": {
        "id": "6BWSmChVqOuh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ^ : 뒤의 문자열로 문자열 시작"
      ],
      "metadata": {
        "id": "gnwc9znvqT-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"^ab\")\n",
        "r.search(\"abcd\") # ^뒤인 ab로 시작하는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJLxeSvRqReg",
        "outputId": "381ef26d-99ea-46aa-f9b7-2d84e32f50e9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ab'>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"ad\") # ^뒤인 ab 중 a로만 시작하는 경우 -> match 안됨"
      ],
      "metadata": {
        "id": "1NfURr7pqe6g"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"cab\")"
      ],
      "metadata": {
        "id": "IakKLgRQqySF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $ : 앞의 문자열로 문자열이 끝남"
      ],
      "metadata": {
        "id": "kxmIjRMertRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab$\")\n",
        "r.search(\"cab\") # $ 앞 문자열 ab로 끝나는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UPlYy9srlwW",
        "outputId": "3b9671a2-5f69-4664-8554-ecea4565a22c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(1, 3), match='ab'>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"cb\") # $ 앞 문자열 ab 중 b로 끝나는 경우 -> match 안됨"
      ],
      "metadata": {
        "id": "NMlzAgVYr0hm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- {숫자} : 숫자만큼 반복"
      ],
      "metadata": {
        "id": "XNExbTGKrc4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{3}c\")\n",
        "r.search(\"abbbc\") # 숫자만큼 반복되는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWXa9uA5q7_U",
        "outputId": "4388ccf0-bcae-4cc3-eae8-c0aad1aebf70"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 5), match='abbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbc\") # 숫자보다 적게 반복되는 경우"
      ],
      "metadata": {
        "id": "qt5OvdlmsBGl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- {숫자1, 숫자2} : 숫자1 이상 숫자2 이하만큼 반복 (?, *, +를 대체 가능)"
      ],
      "metadata": {
        "id": "lF4MTZ0msLLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{1,3}c\")\n",
        "r.search(\"abc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nheIonwKsCXt",
        "outputId": "fd117708-a0db-4b7c-d17b-9a41ab553b31"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbqZUYO8seoS",
        "outputId": "a981ed80-8ed0-4029-a0bd-ff451299c1d3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 4), match='abbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abbbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcUmln7ksbxl",
        "outputId": "e9b37210-b247-4123-b4cf-e7bbf8580bd9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 5), match='abbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"ac\") # 숫자1 미만으로 반복\n",
        "r.search(\"abbbbbc\") # 숫자2 이상으로 반복\n",
        "# -> match 안됨"
      ],
      "metadata": {
        "id": "-ZH8d0Vasgvq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- {숫자,} : 숫자 이상만큼 반복"
      ],
      "metadata": {
        "id": "jOCX8rIzs_6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab{3,}c\")\n",
        "r.search(\"abbbbbbc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ7dilkssiam",
        "outputId": "2e601dc4-9fb8-4028-9e42-596f1a9821ae"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 8), match='abbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"abc\")"
      ],
      "metadata": {
        "id": "QcTT9dadtG51"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [] : 대괄호 내 문자들 중 하나라도 존재하면 매치. -로 범위를 지정할수도 있음"
      ],
      "metadata": {
        "id": "IBebkCPTtMh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[a-zA-Z]\") # 모든알파벳을 의미. 찾는 문자열에 알파벳이 있으면 매치\n",
        "r.search(\"123\")"
      ],
      "metadata": {
        "id": "3B4WvLDotI1l"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"kkt123\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1GNO1ZltiJ-",
        "outputId": "89e876fa-de58-48d4-c0c5-edbc8482c56a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='k'>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[efg]\") # 문자열 내에 e나 f나 g가 있으면 매치\n",
        "r.search(\"eab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x7fe9qctlde",
        "outputId": "e7047bbc-da5a-4582-b2b5-7e95d85959cc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='e'>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"efab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk75oSMZtxnd",
        "outputId": "2fa7f416-5aee-4b2a-c507-b1c1f81a047b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='e'>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [^문자] : 해당 문자 제외한 문자와 매치"
      ],
      "metadata": {
        "id": "POZm0-sEt4jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"[^abc]\")\n",
        "\n",
        "# 아래의 세 코드는 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"a\")\n",
        "r.search(\"ab\")\n",
        "r.search(\"b\")"
      ],
      "metadata": {
        "id": "tT6Ri-XMtzC3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFkvV3XTvKA9",
        "outputId": "495b17e6-fd11-46c2-f222-62beeaa2945e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='d'>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKEWV-CtvLVU",
        "outputId": "ac636540-d4e3-4a2c-f7df-035406ec9828"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='1'>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-2) 정규표현식 모듈 함수"
      ],
      "metadata": {
        "id": "WVvnvXVjul50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- re.compile() : 정규표현식 컴파일 = 파이썬에게 전해주는 역할. 찾으려는 패턴이 빈번한 경우 미리 컴파일해놓고 사용\n",
        "- re.search() : 문자열 전체에서 정규표현식과 매치되는지 검사\n",
        "-re.match() : 문자열의 처음이 정규표현식과 매치되는지 검사"
      ],
      "metadata": {
        "id": "cHg5NkbtvSJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(\"ab.\") # . : 임의의 문자 하나\n",
        "r.match(\"kkkabc\")  #아무런 결과도 출력되지 않는다."
      ],
      "metadata": {
        "id": "fIKZ1BbSuoT6"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.search(\"kkkabc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc-CeiFCvuou",
        "outputId": "106097b3-020d-48a6-d71a-4cf1769e0219"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(3, 6), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- re.split() : 정규표현식 기준으로 문자열 분리 -> 리스트로 리턴"
      ],
      "metadata": {
        "id": "ooUhdu3sv1Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"사과 딸기 수박 메론 바나나\"\n",
        "re.split(\" \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3tPMjw6vzZn",
        "outputId": "341087fd-acca-4392-d225-5e1843ad7f6b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"사과+딸기+수박+메론+바나나\"\n",
        "\n",
        "re.split(\"\\+\",text) # 그냥 +로 하면 안됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT7JR6SAv_Nv",
        "outputId": "6fd89e24-7593-48bf-cd9d-59f0eff596a5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- re.findall() : 정규표현식과 매치되는 모든 경우의 문자열을리스트로 리턴"
      ],
      "metadata": {
        "id": "gUYQLRJsxDd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"이름 : 김철수\n",
        "전화번호 : 010 - 1234 - 1234\n",
        "나이 : 30\n",
        "성별 : 남\"\"\"\n",
        "\n",
        "re.findall(\"\\d+\",text) # \\d+ : 하나 이상의 숫자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bygZMAjswFKu",
        "outputId": "66d25028-6c7a-4791-c089-e62028e062d4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['010', '1234', '1234', '30']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(\"\\d+\", \"문자열입니다.\") # 하나 이상의 숫자가 없는 텍스트에서 찾는 경우"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bYLzKYrxsWf",
        "outputId": "110b31de-ddce-4c4d-8ad7-ee107b7bb224"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- re.finditer() : 정규표현식과 매치되는 모든 경우의 문자열에 대한 이터레이터 객체 리턴\n",
        "- 이터레이터 객체 : 하나씩 순차적으로 값을 반환할 수 있는 객체"
      ],
      "metadata": {
        "id": "o9MJQdhFxzQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"apple banana cherry\"\n",
        "iterator = re.finditer(r\"\\w+\", text) # \\w+ : 하나 이상의 문자 또는 숫자\n",
        "\n",
        "for match in iterator:\n",
        "    print(match.group(), match.start(), match.end())\n",
        "# match.group() : 매치된 단어 (apple, banana, cherry)\n",
        "# match.start() : 매치된 단어의 시작 위치 (0, 6, 13)\n",
        "# match.end() : 매치된 단어의 끝 위치 (5, 12, 19)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXIkV_mDxuJl",
        "outputId": "18632da8-7a15-4cb4-eab8-61a938f3c393"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple 0 5\n",
            "banana 6 12\n",
            "cherry 13 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"apple banana cherry\"\n",
        "iterator = re.finditer(r\"\\w+\", text)\n",
        "for match in iterator:\n",
        "    print(match.group())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbQP09Doyu9b",
        "outputId": "c758f512-b598-4ce6-ed72-1cfebe372ed3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple\n",
            "banana\n",
            "cherry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQWn4uqNyd0I",
        "outputId": "9aacac5e-653d-4de1-8b71-11c25b835bbd"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<callable_iterator object at 0x7b84d33eec50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- re.sub() : 정규 표현식과 일치하는 부분을 다른 문자열로 대체"
      ],
      "metadata": {
        "id": "y-k2CRpbzNRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
        "\n",
        "preprocessed_text = re.sub('[^a-zA-Z]', ' ', text) # text에서 알파벳이 아닌 부분을 공백으로 대체\n",
        "print(preprocessed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgQ4oZLXysS2",
        "outputId": "9f42962e-fa77-4e05-afda-5cd073b9156b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-3) 정규표현식 텍스트 전처리 예제"
      ],
      "metadata": {
        "id": "HHAxwLvZ0kKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "eM_M8TWy1bBW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"100 John    PROF\n",
        "101 James   STUD\n",
        "102 Mac   STUD\"\"\"\n",
        "\n",
        "re.split('\\s+', text) # \\s+ : 1개 이상의 공백 찾아내는 정규표현식 -> 공백 기준 split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKwBNf4dzSP9",
        "outputId": "571824a6-4d1a-4a02-ada9-78985c6f62c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q4X9FJr16Mo",
        "outputId": "7353feb3-c7d2-44a3-820a-b92b9067733c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 John    PROF\n",
            "101 James   STUD\n",
            "102 Mac   STUD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\d+',text) # \\d+ : 1개 이상의 숫자 찾기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5c26g0o1XnX",
        "outputId": "a7a374f0-dcce-4a63-c6f0-38d29f479ff7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', '101', '102']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]',text) # 대문자 찾기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3SoJOCM1k2-",
        "outputId": "0a7f3338-b7b9-441c-81a6-60332c401f8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]{4}',text) # 대문자 4만큼 반복"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmUmenC32DGG",
        "outputId": "fa8123db-dd32-4368-8ab1-c6b4a2472a12"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROF', 'STUD', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z][a-z]+',text) # 대문자 뒤 1개 이상의 소문자\n",
        "#[a-zA-Z]와 다름 주의"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvdTnRx12TDm",
        "outputId": "59016590-7d43-4b55-e92a-965c667fe875"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John', 'James', 'Mac']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Za-z]+',text) # 1개 이상의 대문자, 1개 이상의 소문자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXwRj8Bf2qDk",
        "outputId": "ef5aeb35-35cf-46b5-c33e-ea4a5b01fa31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John', 'PROF', 'James', 'STUD', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-4) 정규표현식을 이용한 토큰화\n",
        "- NLTK의 RegexpTokenizer()"
      ],
      "metadata": {
        "id": "ZuaDyzfc2k8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
        "\n",
        "tokenizer1 = RegexpTokenizer(\"[\\w]+\")  # 문자 또는 숫자가 1개 이상이면 토큰화 (문자, 숫자 기준 토큰화)\n",
        "tokenizer2 = RegexpTokenizer(\"[\\s]+\", gaps=True) # 공백이 1개 이상이면 토큰화 (공백 기준 토큰화)\n",
        "\n",
        "print(tokenizer1.tokenize(text))\n",
        "print(tokenizer2.tokenize(text)) # 문자 제외하지 않고 토큰화 됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqhvgvXp2kSr",
        "outputId": "e9daef80-f97f-4743-9bf9-0eb16f7bfb3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    }
  ]
}